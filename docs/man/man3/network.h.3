.TH "src/network/network.h" 3 "Fri Nov 11 2022" "OCR-Lezcollitade" \" -*- nroff -*-
.ad l
.nh
.SH NAME
src/network/network.h
.SH SYNOPSIS
.br
.PP
\fC#include '\&.\&./utils/matrices/matrix\&.h'\fP
.br

.SS "Classes"

.in +1c
.ti -1c
.RI "struct \fBlayer_activation_t\fP"
.br
.RI "The struct containing all info required about the activation function\&. "
.ti -1c
.RI "struct \fBneuron_t\fP"
.br
.RI "A struct representing a neuron in the network\&. "
.ti -1c
.RI "struct \fBlayer_t\fP"
.br
.RI "A struct representing a layer in the network\&. "
.ti -1c
.RI "struct \fBnetwork_t\fP"
.br
.RI "A struct representing a neural network\&. "
.ti -1c
.RI "struct \fBnetwork_results_t\fP"
.br
.RI "The results of the network\&. "
.in -1c
.SS "Typedefs"

.in +1c
.ti -1c
.RI "typedef struct \fBnetwork_results_t\fP \fBnetwork_results_t\fP"
.br
.ti -1c
.RI "typedef double(* \fBactivation_t\fP) (size_t layer, size_t neuron, double input, \fBnetwork_results_t\fP *results)"
.br
.RI "The activation function type;\&. "
.in -1c
.SS "Functions"

.in +1c
.ti -1c
.RI "\fBneuron_t\fP * \fBneuron_create\fP (\fBmatrix_t\fP *weights, double bias)"
.br
.RI "Creates a neuron\&. "
.ti -1c
.RI "void \fBneuron_free\fP (\fBneuron_t\fP *neuron)"
.br
.RI "Frees the allocated neuron\&. "
.ti -1c
.RI "\fBlayer_t\fP * \fBlayer_create_from_mat\fP (\fBmatrix_t\fP **weights, double *biases, size_t count, \fBlayer_activation_t\fP act)"
.br
.ti -1c
.RI "\fBlayer_t\fP * \fBlayer_create\fP (\fBneuron_t\fP **neurons, size_t count, \fBlayer_activation_t\fP act)"
.br
.ti -1c
.RI "void \fBlayer_free\fP (\fBlayer_t\fP *layer)"
.br
.RI "Frees an allocated layer\&. "
.ti -1c
.RI "\fBnetwork_t\fP * \fBnetwork_create\fP (\fBlayer_t\fP **layers, size_t layer_count, size_t inputs)"
.br
.RI "Creates a network from an array of layers\&. "
.ti -1c
.RI "\fBnetwork_t\fP * \fBnetwork_generate\fP (size_t *neurons, size_t size, \fBlayer_activation_t\fP hidden_activation, \fBlayer_activation_t\fP output_activation)"
.br
.ti -1c
.RI "\fBnetwork_t\fP * \fBnetwork_load\fP (const char *file)"
.br
.RI "Loads the network from a file\&. "
.ti -1c
.RI "void \fBnetwork_save\fP (const char *file, \fBnetwork_t\fP *network)"
.br
.RI "Saves a network to a file\&. "
.ti -1c
.RI "void \fBnetwork_free\fP (\fBnetwork_t\fP *network)"
.br
.RI "Frees the allocated network\&. "
.ti -1c
.RI "void \fBcompute_layer\fP (\fBnetwork_results_t\fP *results, size_t layeri)"
.br
.ti -1c
.RI "\fBmatrix_t\fP * \fBcompute_results\fP (\fBmatrix_t\fP *values, \fBnetwork_t\fP *network)"
.br
.RI "Computes the result of the input by the network\&. "
.ti -1c
.RI "void \fBcompute_results_save\fP (\fBnetwork_results_t\fP *results, \fBnetwork_t\fP *network)"
.br
.RI "Computes the result while saving the result of each layers\&. "
.ti -1c
.RI "\fBnetwork_t\fP * \fBnetwork_copy\fP (\fBnetwork_t\fP *old)"
.br
.RI "Create a deep copied network\&. "
.ti -1c
.RI "void \fBnetwork_train\fP (\fBnetwork_t\fP **pnet, \fBmatrix_t\fP *inputs, \fBmatrix_t\fP *target, double rate)"
.br
.ti -1c
.RI "int \fBnetwork_get_output\fP (\fBmatrix_t\fP *outputs, double threshold)"
.br
.RI "Return the calculated output\&. "
.ti -1c
.RI "\fBnetwork_results_t\fP * \fBresults_create\fP (size_t layer_count)"
.br
.RI "Creates a network_results struct\&. "
.ti -1c
.RI "void \fBresults_free\fP (\fBnetwork_results_t\fP *results)"
.br
.RI "Frees the network results struct\&. "
.in -1c
.SH "Typedef Documentation"
.PP 
.SS "typedef double(* activation_t) (size_t layer, size_t neuron, double input, \fBnetwork_results_t\fP *results)"

.PP
The activation function type;\&. 
.PP
\fBParameters\fP
.RS 4
\fIlayer\fP The index of the layer the activation function is called in\&. 
.br
\fIneuron\fP The index of the neuron the activation function is called in\&. 
.br
\fIinput\fP The value of the neuron before the activation function\&. 
.br
\fIresults\fP The network_results_structures\&. 
.RE
.PP

.PP
Definition at line 17 of file network\&.h\&.
.SS "typedef struct \fBnetwork_results_t\fP \fBnetwork_results_t\fP"

.PP
Definition at line 1 of file network\&.h\&.
.SH "Function Documentation"
.PP 
.SS "void compute_layer (\fBnetwork_results_t\fP * results, size_t layeri)"

.PP
Definition at line 57 of file network\&.c\&.
.PP
.nf
58 {
59     layer_t *layer = results->network->layers[layeri];
60     matrix_t *values = results->outputs[layeri];
61     matrix_t *preactivation = matrix_create(layer->count, 1, 0);
62     for (size_t i = 0; i < layer->count; i++)
63     {
64         neuron_t *neuron = layer->neurons[i];
65         matrix_t *tmp = mat_product(neuron->weights, values);
66         double res = mat_el_at(tmp, 0, 0) + neuron->bias;
67         matrix_free(tmp);
68         mat_set_el(preactivation, i, 0, res);
69     }
70 
71     results->preactivation[layeri] = preactivation;
72     matrix_t *outputs = matrix_create(layer->count, 1, 0);
73     for (size_t i = 0; i < layer->count; i++)
74     {
75         double res = layer->act\&.activation(
76             layeri, i, mat_el_at(preactivation, i, 0), results);
77         mat_set_el(outputs, i, 0, res);
78     }
79 
80     results->outputs[layeri + 1] = outputs;
81 }
.fi
.SS "\fBmatrix_t\fP* compute_results (\fBmatrix_t\fP * values, \fBnetwork_t\fP * network)"

.PP
Computes the result of the input by the network\&. 
.PP
\fBParameters\fP
.RS 4
\fIinputs\fP The column vector of the values\&. 
.br
\fInetwork\fP The network to apply the values to\&. 
.RE
.PP
\fBReturns\fP
.RS 4
The column vector of the computed results\&. 
.RE
.PP

.PP
Definition at line 83 of file network\&.c\&.
.PP
.nf
84 {
85     matrix_t *last_results = mat_copy(values);
86     network_results_t *results = results_create(network->layer_count);
87     results->network = network;
88     results->outputs[0] = last_results;
89     compute_results_save(results, network);
90     matrix_t *res = mat_copy(results->outputs[network->layer_count]);
91     results_free(results);
92     return res;
93 }
.fi
.SS "void compute_results_save (\fBnetwork_results_t\fP * results, \fBnetwork_t\fP * network)"

.PP
Computes the result while saving the result of each layers\&. 
.PP
\fBParameters\fP
.RS 4
\fIresults\fP The results struct\&. 
.br
\fInetwork\fP The network to compute the results from\&. 
.RE
.PP

.PP
Definition at line 95 of file network\&.c\&.
.PP
.nf
96 {
97     for (size_t i = 0; i < network->layer_count; i++)
98     {
99         compute_layer(results, i);
100     }
101 }
.fi
.SS "\fBlayer_t\fP* layer_create (\fBneuron_t\fP ** neurons, size_t count, \fBlayer_activation_t\fP act)"

.PP
Definition at line 140 of file network\&.c\&.
.PP
.nf
141 {
142     layer_t *layer = (layer_t *)malloc(sizeof(layer_t));
143     if (layer == NULL)
144         return NULL;
145     layer->neurons = neurons;
146     layer->count = count;
147     layer->act = act;
148 
149     return layer;
150 }
.fi
.SS "\fBlayer_t\fP* layer_create_from_mat (\fBmatrix_t\fP ** weights, double * biases, size_t count, \fBlayer_activation_t\fP act)"

.PP
Definition at line 120 of file network\&.c\&.
.PP
.nf
122 {
123     layer_t *layer = (layer_t *)malloc(sizeof(layer_t));
124     if (layer == NULL)
125         return NULL;
126     layer->count = count;
127     layer->neurons = (neuron_t **)malloc(count * sizeof(neuron_t *));
128     if (layer->neurons == NULL)
129     {
130         free(layer);
131         return NULL;
132     }
133     layer->act = act;
134     for (size_t i = 0; i < count; i++)
135         layer->neurons[i] = neuron_create(weights[i], biases[i]);
136 
137     return layer;
138 }
.fi
.SS "void layer_free (\fBlayer_t\fP * layer)"

.PP
Frees an allocated layer\&. 
.PP
\fBParameters\fP
.RS 4
\fIlayer\fP The layer to be freed\&. 
.RE
.PP

.PP
Definition at line 152 of file network\&.c\&.
.PP
.nf
153 {
154     for (size_t i = 0; i < layer->count; i++)
155     {
156         neuron_free(layer->neurons[i]);
157     }
158 
159     free(layer->neurons);
160     free(layer);
161 }
.fi
.SS "\fBnetwork_t\fP* network_copy (\fBnetwork_t\fP * old)"

.PP
Create a deep copied network\&. 
.PP
\fBParameters\fP
.RS 4
\fIold\fP The network to copy\&. 
.RE
.PP
\fBReturns\fP
.RS 4
The copied network\&. 
.RE
.PP

.PP
Definition at line 588 of file network\&.c\&.
.PP
.nf
589 {
590     layer_t **layers
591         = (layer_t **)malloc(old->layer_count * sizeof(layer_t *));
592     network_t *res = network_create(layers, old->layer_count, old->inputs);
593     for (size_t i = 0; i < old->layer_count; i++)
594     {
595         layers[i] = layer_copy(old->layers[i]);
596     }
597 
598     return res;
599 }
.fi
.SS "\fBnetwork_t\fP* network_create (\fBlayer_t\fP ** layers, size_t layer_count, size_t inputs)"

.PP
Creates a network from an array of layers\&. 
.PP
\fBParameters\fP
.RS 4
\fIlayers\fP The array of layers in the network\&. 
.br
\fIsize\fP The number of layers in the array\&. 
.br
\fIinputs\fP The number of neurons in the input layer\&. 
.RE
.PP
\fBReturns\fP
.RS 4
The created network\&. 
.RE
.PP

.PP
Definition at line 163 of file network\&.c\&.
.PP
.nf
164 {
165     network_t *res = (network_t *)malloc(sizeof(network_t));
166     if (res == NULL)
167         return NULL;
168     res->layers = layers;
169     res->inputs = inputs;
170     res->layer_count = layer_count;
171     return res;
172 }
.fi
.SS "void network_free (\fBnetwork_t\fP * net)"

.PP
Frees the allocated network\&. 
.PP
\fBParameters\fP
.RS 4
\fInetwork\fP The network to be freed\&. 
.RE
.PP

.PP
Definition at line 174 of file network\&.c\&.
.PP
.nf
175 {
176     for (size_t i = 0; i < net->layer_count; i++)
177     {
178         layer_free(net->layers[i]);
179     }
180 
181     free(net->layers);
182     free(net);
183 }
.fi
.SS "\fBnetwork_t\fP* network_generate (size_t * neurons, size_t size, \fBlayer_activation_t\fP hidden_activation, \fBlayer_activation_t\fP output_activation)"

.PP
Definition at line 541 of file network\&.c\&.
.PP
.nf
543 {
544     if (size < 2)
545         return NULL;
546     layer_t **layers = (layer_t **)malloc((size - 1) * sizeof(layer_t *));
547     size_t weights = neuron_count[0];
548     network_t *res = network_create(layers, size - 1, weights);
549 
550     for (size_t i = 1; i < size; i++)
551     {
552         size_t n_count = neuron_count[i];
553         neuron_t **neurons = (neuron_t **)malloc(n_count * sizeof(neuron_t *));
554         layer_t *layer = layer_create(neurons, n_count, hidden_activation);
555         layers[i - 1] = layer;
556         for (size_t ni = 0; ni < n_count; ni++)
557         {
558             double *values = generate_weights(weights + 1);
559             layers[i - 1]->neurons[ni] = parse_results(values, weights);
560             free(values);
561         }
562         weights = n_count;
563     }
564 
565     layer_t *out = res->layers[res->layer_count - 1];
566     out->act = output_activation;
567 
568     return res;
569 }
.fi
.SS "int network_get_output (\fBmatrix_t\fP * outputs, double threshold)"

.PP
Return the calculated output\&. 
.PP
\fBParameters\fP
.RS 4
\fIoutputs\fP The matrix of outputs given by the network\&. 
.br
\fIthreshold\fP The threshold starting from which the result will be considered as valid\&. 
.RE
.PP
\fBReturns\fP
.RS 4
The calculated output or -1 if none above the threshold\&. 
.RE
.PP

.PP
Definition at line 715 of file network\&.c\&.
.PP
.nf
716 {
717     int result = -1;
718     double old_value = 0;
719     for (size_t i = 0; i < outputs->rows; i++)
720     {
721         double val = mat_el_at(outputs, i, 0);
722         if (val < threshold)
723             continue;
724         if (val > old_value)
725         {
726             result = i;
727             old_value = val;
728         }
729     }
730 
731     return result;
732 }
.fi
.SS "\fBnetwork_t\fP* network_load (const char * file)"

.PP
Loads the network from a file\&. 
.PP
\fBParameters\fP
.RS 4
\fIfile\fP The path of the file to load\&. 
.RE
.PP
\fBReturns\fP
.RS 4
The loaded network\&. The file format: The file will start with two comma-separated integer indicating the number of layers and the number of input neurons\&. Each layer will start by the number of neurons in the layer\&. Then each neuron information will be seperated by a newline char\&. Neuron format: <weight1>, \&.\&.\&. , <weightn>, <bias> Example for xor network with random biases and weights: 2,2 # The number of layers and the number of input neurons\&. 2 # The number of neurons in layer 1 1,1,-0\&.5 # neuron 1,1 weights are [1, 1] and the bias is -0\&.5 -1,-1,1\&.5 1 # The number of neurons in layer 2 1, 1, 0\&.5 
.RE
.PP

.PP
Definition at line 445 of file network\&.c\&.
.PP
.nf
446 {
447     // open the file
448     FILE *file = fopen(path, "r");
449     CHK(file, "network_load", "could not open file");
450 
451     size_t layer_count, weight_count, neuron_count = 0;
452     size_t neuron_index = 0, layer_index = 0;
453     int in_layer = 0;
454     size_t line = 0;
455     int alive = parse_header(file, &layer_count, &neuron_count, &line);
456     line++;
457     if (!alive)
458         return NULL;
459 
460     layer_t **layers = (layer_t **)malloc(layer_count * sizeof(layer_t *));
461     network_t *res = network_create(layers, layer_count, neuron_count);
462     double *values;
463     char *activation_name = NULL;
464     while (layer_index < layer_count)
465     {
466         if (!in_layer)
467         {
468             weight_count = neuron_count;
469             alive = parse_layer_header(
470                 file, &neuron_count, &line, &activation_name);
471             layer_activation_t act = get_layer_activation(activation_name);
472             if (activation_name != NULL)
473                 free(activation_name);
474             line++;
475             neuron_index = 0;
476             in_layer = 1;
477             layers[layer_index] = layer_create(
478                 (neuron_t **)malloc(neuron_count * sizeof(neuron_t *)),
479                 neuron_count, act);
480         }
481         else
482         {
483             if (neuron_count == neuron_index)
484             {
485                 in_layer = 0;
486                 layer_index++;
487             }
488             else
489             {
490                 values = (double *)malloc((weight_count + 1) * sizeof(double));
491                 alive
492                     = parse_neuron_line(file, values, weight_count + 1, &line);
493                 line++;
494                 layers[layer_index]->neurons[neuron_index]
495                     = parse_results(values, weight_count);
496                 free(values);
497                 neuron_index++;
498             }
499         }
500     }
501     // close the file
502     fclose(file);
503     return res;
504 }
.fi
.SS "void network_save (const char * path, \fBnetwork_t\fP * net)"

.PP
Saves a network to a file\&. 
.PP
\fBParameters\fP
.RS 4
\fIfile\fP The file to save the network to\&. 
.br
\fInetwork\fP The network to be saved\&. 
.RE
.PP

.PP
Definition at line 526 of file network\&.c\&.
.PP
.nf
527 {
528     FILE *file = fopen(path, "w");
529     CHK(file, "network_save", "could not open file");
530     fprintf(file, "%zu, %zu\n", net->layer_count, net->inputs);
531     size_t weight_count = net->inputs;
532     for (size_t i = 0; i < net->layer_count; i++)
533     {
534         fprintf(file, "\n");
535         layer_save(file, net->layers[i], weight_count);
536         weight_count = net->layers[i]->count;
537     }
538     fclose(file);
539 }
.fi
.SS "void network_train (\fBnetwork_t\fP ** pnet, \fBmatrix_t\fP * inputs, \fBmatrix_t\fP * target, double rate)"

.PP
Definition at line 672 of file network\&.c\&.
.PP
.nf
674 {
675     network_t *trained = network_copy(*pnet);
676 
677     network_results_t *results = results_create((*pnet)->layer_count);
678     results->network = *pnet;
679 
680     matrix_t **outputs = results->outputs;
681     outputs[0] = mat_copy(inputs);
682 
683     matrix_t **deltas
684         = (matrix_t **)malloc((*pnet)->layer_count * sizeof(matrix_t *));
685 
686     compute_results_save(results, *pnet);
687 
688     size_t layer_i = trained->layer_count - 1;
689     layer_t *trained_layer = trained->layers[layer_i];
690     layer_t *old_layer = (*pnet)->layers[layer_i];
691     deltas[layer_i] = matrix_create(trained_layer->count, 1, 0);
692     for (size_t ni = 0; ni < trained_layer->count; ni++)
693     {
694         double delta = output_neuron_train(trained_layer->neurons[ni],
695             old_layer->neurons[ni], rate, mat_el_at(target, ni, 0),
696             mat_el_at(outputs[layer_i + 1], ni, 0), results, layer_i, ni,
697             old_layer->act\&.dactivation);
698         mat_set_el(deltas[layer_i], ni, 0, delta);
699     }
700 
701     compute_deltas(results, *pnet, deltas);
702     hidden_layer_train(results, trained, deltas, rate);
703 
704     results_free(results);
705 
706     for (size_t i = 1; i <= trained->layer_count; i++)
707     {
708         matrix_free(deltas[i - 1]);
709     }
710     free(deltas);
711     network_free(*pnet);
712     *pnet = trained;
713 }
.fi
.SS "\fBneuron_t\fP* neuron_create (\fBmatrix_t\fP * weights, double bias)"

.PP
Creates a neuron\&. 
.PP
\fBParameters\fP
.RS 4
\fIweights\fP The weights of the neuron\&. 
.br
\fIbias\fP The bias of the neuron\&. 
.RE
.PP
\fBReturns\fP
.RS 4
The instantiated neuron\&. 
.RE
.PP

.PP
Definition at line 103 of file network\&.c\&.
.PP
.nf
104 {
105     neuron_t *neuron = (neuron_t *)malloc(sizeof(neuron_t));
106     if (neuron == NULL)
107         return NULL;
108     neuron->weights = weights;
109     neuron->bias = bias;
110 
111     return neuron;
112 }
.fi
.SS "void neuron_free (\fBneuron_t\fP * neuron)"

.PP
Frees the allocated neuron\&. 
.PP
\fBParameters\fP
.RS 4
\fIneuron\fP The neuron to free\&. 
.RE
.PP

.PP
Definition at line 114 of file network\&.c\&.
.PP
.nf
115 {
116     matrix_free(neuron->weights);
117     free(neuron);
118 }
.fi
.SS "\fBnetwork_results_t\fP* results_create (size_t layer_count)"

.PP
Creates a network_results struct\&. 
.PP
\fBParameters\fP
.RS 4
\fIlayer_count\fP The number of layers in the network\&. 
.RE
.PP
\fBReturns\fP
.RS 4
The created structure\&. 
.RE
.PP

.PP
Definition at line 14 of file network\&.c\&.
.PP
.nf
15 {
16     network_results_t *results
17         = (network_results_t *)malloc(sizeof(network_results_t));
18     if (results == NULL)
19         return NULL;
20     results->preactivation
21         = (matrix_t **)calloc(layer_count, sizeof(matrix_t *));
22     if (results->preactivation == NULL)
23     {
24         free(results);
25         return NULL;
26     }
27     results->outputs
28         = (matrix_t **)calloc(layer_count + 1, sizeof(matrix_t *));
29     if (results->outputs == NULL)
30     {
31         free(results->preactivation);
32         free(results);
33         return NULL;
34     }
35 
36     return results;
37 }
.fi
.SS "void results_free (\fBnetwork_results_t\fP * results)"

.PP
Frees the network results struct\&. 
.PP
\fBParameters\fP
.RS 4
\fIresults\fP The results struct to free\&. 
.RE
.PP

.PP
Definition at line 39 of file network\&.c\&.
.PP
.nf
40 {
41     for (size_t i = 0; i < results->network->layer_count; i++)
42     {
43         if (results->preactivation[i] != NULL)
44             matrix_free(results->preactivation[i]);
45     }
46     for (size_t i = 0; i <= results->network->layer_count; i++)
47     {
48         if (results->outputs[i] != NULL)
49             matrix_free(results->outputs[i]);
50     }
51 
52     free(results->preactivation);
53     free(results->outputs);
54     free(results);
55 }
.fi
.SH "Author"
.PP 
Generated automatically by Doxygen for OCR-Lezcollitade from the source code\&.
